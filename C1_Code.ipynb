{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras_preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "#1번째 모델 불러오기\n",
    "model = load_model('cluster_G3G5G13_together.h5')\n",
    "\n",
    "#2번째 모델 불러오기\n",
    "second_AEST_model = load_model('trainonlyATSE.h5')\n",
    "second_MN_model = load_model('trainonlyMN.h5')\n",
    "second_RU_model = load_model('trainonlyRU.h5')\n",
    "second_VW_model = load_model('trainonlyVW.h5')\n",
    "second_GH_model = load_model('trainonlyGH.h5')\n",
    "second_YBCDFIKLOPQX_model = load_model('C1_Add_Group.h5')\n",
    "\n",
    "#시각화 정의\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "def match_group(GroupID,i, groupidx, clusterID,ax ):\n",
    "    print(trainAlphalist[np.argmax(prediction[i])] , GroupID)\n",
    "    if (trainAlphalist[np.argmax(prediction[i])] == GroupID):\n",
    "        group_maxval = []\n",
    "        for g1item in groupidx:\n",
    "            group_maxval.append(sec_prediction[i][g1item])\n",
    "            print(\"A\",sec_prediction[i][g1item] )\n",
    "        #print(\"AA:\", filename[i], clusterID[int(np.argmax(group_maxval))])\n",
    "        ax.text(0.05, 0.75, clusterID[int(np.argmax(group_maxval))], fontsize=15,\n",
    "                # ax.text(0.05, 0.05,  chr(65 + np.argmax(prediction[i])),fontsize=20,\n",
    "                transform=ax.transAxes,\n",
    "                color='red' if clusterID[int(np.argmax(group_maxval))] != filename[i].split(\"_\")[1][0] else 'blue')\n",
    "        return ax,clusterID[int(np.argmax(group_maxval))]\n",
    "\n",
    "#테스트셋 불러오기\n",
    "test_DIR = \"Fix_Testset\"\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "# test_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
    "#                                   rotation_range=20,\n",
    "#                                   zoom_range=0.2,\n",
    "#                                   fill_mode='nearest')\n",
    "test_generator = test_datagen.flow_from_directory(test_DIR,\n",
    "                                                  batch_size=256,\n",
    "                                                  shuffle = False,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  target_size=(64, 64))\n",
    "\n",
    "#테스트 셋\n",
    "print(test_generator.n)\n",
    "trainAlphalist = ['G1','G2', 'G3', 'G4', 'G5', 'G6']\n",
    "# 테스트의 알파벳 디렉토리 순서와 동일하게 적기\n",
    "testAlphalist = ['G1', 'G2', 'G3', 'G4', 'G5', 'G6']\n",
    "\n",
    "sec_trainAlphalist = ['A',  'B', 'C,', 'D', 'E', 'F', 'G','H', 'I','K','L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V','W','X','Y']\n",
    "# 테스트의 알파벳 디렉토리 순서와 동일하게 적기\n",
    "sec_testAlphalist = ['G1','G2', 'G3', 'G4', 'G5', 'G6']\n",
    "\n",
    "G1_cluster=['A','E','S','T']\n",
    "G2_cluster= ['M','N']\n",
    "G3_cluster= ['R','U']\n",
    "G4_cluster= ['V','W']\n",
    "G5_cluster= ['G','H']\n",
    "G6_cluster= ['Y','B','C','D','F','I','K','L','O','P','Q','X']\n",
    "\n",
    "g1=[]\n",
    "g1.append(0)\n",
    "g1.append(1)\n",
    "g1.append(2)\n",
    "g1.append(3)\n",
    "\n",
    "g2=[]\n",
    "g2.append(0)\n",
    "g2.append(1)\n",
    "\n",
    "g3=[]\n",
    "g3.append(0)\n",
    "g3.append(1)\n",
    "\n",
    "g4=[]\n",
    "g4.append(0)\n",
    "g4.append(1)\n",
    "\n",
    "g5=[]\n",
    "g5.append(0)\n",
    "g5.append(1)\n",
    "\n",
    "g6=[]\n",
    "g6.append(0)\n",
    "g6.append(1)\n",
    "g6.append(2)\n",
    "g6.append(3)\n",
    "g6.append(4)\n",
    "g6.append(5)\n",
    "g6.append(6)\n",
    "g6.append(7)\n",
    "g6.append(8)\n",
    "g6.append(9)\n",
    "g6.append(10)\n",
    "g6.append(11)\n",
    "\n",
    "fig, axes = plt.subplots(25, 10, figsize=(40, 40),\n",
    "                         subplot_kw={'xticks': [], 'yticks': []},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "x, y = test_generator.next()\n",
    "filename = test_generator.filenames\n",
    "\n",
    "# second_AEST_model = load_model('trainonlyATSE.h5')\n",
    "# second_MN_model = load_model('trainonlyMN.h5')\n",
    "# second_RU_model = load_model('trainonlyRU.h5')\n",
    "# second_VW_model = load_model('trainonlyVW.h5')\n",
    "# second_GH_model = load_model('trainonlyGH.h5')\n",
    "# second_YBCDFIKLOPQX_model = load_model('C1_Add_Group.h5')\n",
    "\n",
    "prediction = model.predict(x)\n",
    "print(\"예측 (예측 알파벳)\\t\\t\\t\\t\\t\\t\\t softmax 예측 값 \\t (실제알파벳)\\t실제라벨  \")\n",
    "errcnt = 0\n",
    "alphalist_cor={}\n",
    "alphalist_incor= {}\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    try:\n",
    "        image = x[i]\n",
    "        ax.imshow(image)\n",
    "        # print(prediction[i])\n",
    "        if filename[i].split(\"_\")[1][0] not in alphalist_cor:\n",
    "            alphalist_cor[filename[i].split(\"_\")[1][0]] = 0\n",
    "        if filename[i].split(\"_\")[1][0] not in alphalist_incor:\n",
    "            alphalist_incor[filename[i].split(\"_\")[1][0]] = 0\n",
    "\n",
    "            \n",
    "        if (testAlphalist[np.argmax(y[i])] ==\"G1\"):\n",
    "            sec_prediction = second_AEST_model.predict(x)\n",
    "        elif (testAlphalist[np.argmax(y[i])] ==\"G2\"):\n",
    "            sec_prediction = second_MN_model.predict(x)\n",
    "        elif (testAlphalist[np.argmax(y[i])] ==\"G3\"):\n",
    "            sec_prediction = second_RU_model.predict(x)\n",
    "        elif (testAlphalist[np.argmax(y[i])] ==\"G4\"):\n",
    "            sec_prediction = second_VW_model.predict(x)\n",
    "        elif (testAlphalist[np.argmax(y[i])] == \"G5\"):\n",
    "            sec_prediction = second_GH_model.predict(x)\n",
    "        elif (testAlphalist[np.argmax(y[i])] == \"G6\"):\n",
    "            sec_prediction = second_YBCDFIKLOPQX_model.predict(x)    \n",
    "\n",
    "\n",
    "        print(i, y[i], \"\\t\", np.argmax(prediction[i]), \"-\", trainAlphalist[np.argmax(prediction[i])], \"\\t\\t\",\n",
    "              np.argmax(y[i]), \"-\", testAlphalist[np.argmax(y[i])], \"\\t\", np.max(prediction[i]), \"\\t\",np.max(sec_prediction[i]))\n",
    "        # 맞으면 파란색 틀리면 빨간색\n",
    "        ax.text(0.05, 0.05, trainAlphalist[np.argmax(prediction[i])], fontsize=10,\n",
    "                # ax.text(0.05, 0.05,  chr(65 + np.argmax(prediction[i])),fontsize=20,\n",
    "                transform=ax.transAxes,\n",
    "                color='red' if testAlphalist[np.argmax(y[i])] != trainAlphalist[np.argmax(prediction[i])] else 'blue')\n",
    "        #?\n",
    "        if testAlphalist[np.argmax(y[i]) ] != trainAlphalist[np.argmax(prediction[i])]:\n",
    "            errcnt += 1\n",
    "            if filename[i].split(\"/\")[0] == \"G8\":\n",
    "                print(\"ssss\")\n",
    "            alphalist_incor[filename[i].split(\"_\")[1][0]] += 1\n",
    "\n",
    "        if(filename[i].split(\"/\")[0]) == \"G1\":  # A,E,S,T\n",
    "            ax,predict_alpha = match_group('G1', i, g1, G1_cluster,ax )\n",
    "        elif(filename[i].split(\"/\")[0]) == \"G2\" : #M,N\n",
    "            ax,predict_alpha = match_group('G2', i, g2, G2_cluster,ax)\n",
    "        elif (filename[i].split(\"/\")[0]) == \"G3\":  # R,U\n",
    "            ax, predict_alpha = match_group('G3', i, g3, G3_cluster, ax)\n",
    "        elif (filename[i].split(\"/\")[0]) == \"G4\":  # V,W\n",
    "            ax, predict_alpha = match_group('G4', i, g4, G4_cluster, ax)\n",
    "        elif (filename[i].split(\"/\")[0]) == \"G5\":  # G,H\n",
    "            ax, predict_alpha = match_group('G5', i, g5, G5_cluster, ax)\n",
    "        elif (filename[i].split(\"/\")[0]) == \"G6\":  # Y,B,C....\n",
    "            ax, predict_alpha = match_group('G6', i, g6, G6_cluster, ax)\n",
    "\n",
    "        # 그룹에 여러 알파벳있는 그룹\n",
    "        else:\n",
    "            if filename[i].split(\"_\")[1][0] == predict_alpha:\n",
    "                alphalist_cor[filename[i].split(\"_\")[1][0]] += 1\n",
    "            else:\n",
    "                alphalist_incor[filename[i].split(\"_\")[1][0]] += 1\n",
    "    except:\n",
    "        continue\n",
    "print(\"Error Rate : \", errcnt / test_generator.n)\n",
    "print(test_generator.n,errcnt )\n",
    "plt.show()\n",
    "\n",
    "total_correct= 0\n",
    "total_incorrect= 0\n",
    "for i in alphalist_cor:\n",
    "    total_correct += alphalist_cor[i]\n",
    "    total_incorrect += alphalist_incor[i]\n",
    "    print(i, alphalist_cor[i], alphalist_incor[i])#, alphalist_cor[i]/(alphalist_cor[i]+alphalist_incor[i]))\n",
    "print(total_correct,total_incorrect,float(total_incorrect/(total_incorrect+total_correct)))\n",
    "#plt.show()\n",
    "plt.savefig('./fig1_all_17group.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
